{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch_local/arubinstein17-163577/starlight'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# import copy\n",
    "# import h5py\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "from IPython.display import display\n",
    "# import random\n",
    "# import matplotlib.ticker as ticker\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import itertools\n",
    "# import sklearn\n",
    "\n",
    "\n",
    "# local imports\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    os.path.join(\n",
    "        os.path.dirname(os.path.abspath(''))\n",
    "    )\n",
    ")\n",
    "from dataloaders.cifar10 import (\n",
    "    load_cifar10\n",
    ")\n",
    "from models import models_dict as MODELS_DICT\n",
    "# models_dict = {\n",
    "#     \"resnet18_cifar\": resnet18_cifar,\n",
    "#     \"resnet18_torch\": torchvision.models.resnet18,\n",
    "#     \"resnet50_torch\": torchvision.models.resnet50,\n",
    "#     \"densenet_cifar\": densenet_cifar\n",
    "# }\n",
    "sys.path.pop(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(raw_link):\n",
    "    id = raw_link.split(\"/d/\")[-1].split(\"/\")[0]\n",
    "    return f\"https://drive.google.com/uc?id={id}\"\n",
    "\n",
    "\n",
    "def get_model(chkpt_path, model_name, model_settings={}):\n",
    "    model = MODELS_DICT[model_name](**model_settings)\n",
    "    model.load_state_dict(torch.load(chkpt_path)[\"state_dict\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_resnet18_cifar(chkpt_path):\n",
    "    return get_model(\n",
    "        chkpt_path,\n",
    "        \"resnet18_cifar\",\n",
    "        model_settings={\"num_classes\": 10}\n",
    ")\n",
    "\n",
    "# @torch.no_grad\n",
    "# def compute_margin_for_batch(model_1, model_2, x, device=\"cuda:0\"):\n",
    "\n",
    "#     x.requires_grad = True\n",
    "\n",
    "#     with torch.enable_grad():\n",
    "#         output_1 = model_1(x)\n",
    "#         output_2 = model_2(x)\n",
    "\n",
    "#     output_1 = output_1.to(device)\n",
    "#     output_2 = output_2.to(device)\n",
    "\n",
    "#     num_classes = output_1.shape[-1]\n",
    "#     margins_for_all_class_pairs = []\n",
    "#     used_classes = range(num_classes)\n",
    "\n",
    "#     first_model_grads = {}\n",
    "#     second_model_grads = {}\n",
    "\n",
    "#     with torch.enable_grad():\n",
    "#         for class_i in used_classes:\n",
    "#             first_model_grads[class_i] = get_grad(\n",
    "#                 output_1[..., class_i],\n",
    "#                 x,\n",
    "#                 retain_graph=True\n",
    "#             )\n",
    "#             second_model_grads[class_i] = get_grad(\n",
    "#                 output_2[..., class_i],\n",
    "#                 x,\n",
    "#                 retain_graph=(class_i != num_classes - 1)\n",
    "#             )\n",
    "\n",
    "#     cartesian_product = list(itertools.product(used_classes, repeat=2))\n",
    "#     for i, (class_i, class_j) in (enumerate(cartesian_product)):\n",
    "\n",
    "#         if class_i == class_j:\n",
    "#             continue\n",
    "\n",
    "#         output_1_i = output_1[..., class_i]\n",
    "#         output_2_j = output_2[..., class_j]\n",
    "\n",
    "#         grad_1_i = first_model_grads[class_i]\n",
    "#         grad_2_j = second_model_grads[class_j]\n",
    "#         batch_margins_for_class_pair = compute_margin(\n",
    "#             output_1_i,\n",
    "#             output_2_j,\n",
    "#             grad_1_i,\n",
    "#             grad_2_j,\n",
    "#             norm=\"l1\"\n",
    "#         )\n",
    "\n",
    "#         margins_for_all_class_pairs.append(batch_margins_for_class_pair.mean())\n",
    "#     return torch.Tensor(margins_for_all_class_pairs).mean()\n",
    "\n",
    "\n",
    "@torch.no_grad\n",
    "def compute_margin_for_batch(model, x, device=\"cuda:0\"):\n",
    "\n",
    "    x.requires_grad = True\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        output = model(x)\n",
    "\n",
    "    output = output.to(device)\n",
    "\n",
    "    num_classes = output.shape[-1]\n",
    "    margins_for_all_class_pairs = []\n",
    "    used_classes = range(num_classes)\n",
    "\n",
    "    model_grads = {}\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        for class_i in used_classes:\n",
    "            model_grads[class_i] = get_grad(\n",
    "                output[..., class_i],\n",
    "                x,\n",
    "                retain_graph=True\n",
    "            )\n",
    "\n",
    "    # cartesian_product = list(itertools.product(used_classes, repeat=2))\n",
    "    # for i, (class_i, class_j) in (enumerate(cartesian_product)):\n",
    "    for i in range(len(used_classes)):\n",
    "        for j in range(i + 1, len(used_classes)):\n",
    "\n",
    "            class_i = used_classes[i]\n",
    "            class_j = used_classes[j]\n",
    "\n",
    "            output_i = output[..., class_i]\n",
    "            output_j = output[..., class_j]\n",
    "\n",
    "            grad_i = model_grads[class_i]\n",
    "            grad_j = model_grads[class_j]\n",
    "            batch_margins_for_class_pair = compute_margin(\n",
    "                output_i,\n",
    "                output_j,\n",
    "                grad_i,\n",
    "                grad_j,\n",
    "                norm=\"l1\"\n",
    "            )\n",
    "\n",
    "            margins_for_all_class_pairs.append(batch_margins_for_class_pair.mean())\n",
    "    return torch.Tensor(margins_for_all_class_pairs).mean()\n",
    "\n",
    "\n",
    "def get_grad(output_i, x, retain_graph):\n",
    "    assert x.requires_grad == True\n",
    "    differentiable_value = output_i.sum()\n",
    "    differentiable_value.backward(inputs=x, retain_graph=retain_graph)\n",
    "    grad = x.grad\n",
    "    x.grad = None\n",
    "    return grad\n",
    "\n",
    "\n",
    "def compute_margin(output_i, output_j, grad_i, grad_j, norm=\"l1\"):\n",
    "    # eq. 7 here: https://proceedings.neurips.cc/paper_files/paper/2018/file/42998cf32d552343bc8e460416382dca-Paper.pdf\n",
    "    # d = |f_i(x) - f_j(x)| / |grad_x f_i(x) - grad_x f_j (x)|_q\n",
    "    assert norm == \"l1\"\n",
    "    if norm == \"l1\":\n",
    "        return (\n",
    "                (output_i - output_j).abs()\n",
    "            /\n",
    "                (grad_i - grad_j).abs().sum()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only L1 norm is supported\")\n",
    "\n",
    "\n",
    "# def margin_on_dataloader(\n",
    "#     model_1,\n",
    "#     model_2,\n",
    "#     dataloader,\n",
    "#     percent=0.01,\n",
    "#     device=\"cuda:0\"\n",
    "# ):\n",
    "\n",
    "#     model_1.eval()\n",
    "#     model_2.eval()\n",
    "#     model_1.to(device)\n",
    "#     model_2.to(device)\n",
    "#     dataloader_len = len(dataloader)\n",
    "#     if percent == 1:\n",
    "#         active_batches = list(range(dataloader_len))\n",
    "#     else:\n",
    "#         total_batches = int(percent * dataloader_len)\n",
    "#         active_batches = np.linspace(0, dataloader_len, total_batches)\n",
    "#         active_batches = active_batches.astype(int)\n",
    "\n",
    "#     res = []\n",
    "#     pb = tqdm(total=dataloader_len, desc='batch', position=0)\n",
    "#     for i, batch in (enumerate(dataloader)):\n",
    "#         pb.update(1)\n",
    "#         if i not in active_batches:\n",
    "#             continue\n",
    "#         x, y = batch\n",
    "#         x = x.to(device)\n",
    "#         batch_margin = compute_margin_for_batch(\n",
    "#             model_1,\n",
    "#             model_2,\n",
    "#             x,\n",
    "#             device=device\n",
    "#         )\n",
    "#         res.append(batch_margin)\n",
    "#     return torch.Tensor(res).mean().item()\n",
    "\n",
    "\n",
    "def margin_on_dataloader(\n",
    "    model,\n",
    "    dataloader,\n",
    "    percent=0.01,\n",
    "    device=\"cuda:0\"\n",
    "):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "    if percent == 1:\n",
    "        active_batches = list(range(dataloader_len))\n",
    "    else:\n",
    "        total_batches = int(percent * dataloader_len)\n",
    "        active_batches = np.linspace(0, dataloader_len, total_batches)\n",
    "        active_batches = active_batches.astype(int)\n",
    "\n",
    "    res = []\n",
    "    pb = tqdm(total=dataloader_len, desc='batch', position=0)\n",
    "    for i, batch in (enumerate(dataloader)):\n",
    "        pb.update(1)\n",
    "        if i not in active_batches:\n",
    "            continue\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        batch_margin = compute_margin_for_batch(\n",
    "            model,\n",
    "            x,\n",
    "            device=device\n",
    "        )\n",
    "        res.append(batch_margin)\n",
    "    return torch.Tensor(res).mean().item()\n",
    "\n",
    "\n",
    "# def compute_results(\n",
    "#     anchors,\n",
    "#     stars,\n",
    "#     dataloader,\n",
    "#     cache_path,\n",
    "#     percent=1,\n",
    "#     load_model=get_resnet18_cifar,\n",
    "#     recompute_substring=None\n",
    "# ):\n",
    "#     res = {}\n",
    "#     if os.path.exists(cache_path):\n",
    "#         print(f\"Loading existing results from {cache_path}\")\n",
    "#         res = torch.load(cache_path)\n",
    "#     else:\n",
    "#         res = {}\n",
    "#     all_model_pairs = list(itertools.product(anchors + stars, repeat=2))\n",
    "#     dataset_root = dataloader.dataset.dataset.__dict__[\"root\"]\n",
    "#     for model_1, model_2 in all_model_pairs:\n",
    "#         if model_1 == model_2:\n",
    "#             continue\n",
    "\n",
    "#         df_id = f\"{model_1}_{model_2}_{dataset_root}_p{percent}\"\n",
    "#         to_recompute = (not df_id in res)\n",
    "#         if not to_recompute and recompute_substring is not None:\n",
    "#             to_recompute = recompute_substring in df_id\n",
    "\n",
    "#         if to_recompute:\n",
    "#             print(f\"Computing results for {df_id}\")\n",
    "#             res[df_id] = margin_on_dataloader(\n",
    "#                 load_model(model_1),\n",
    "#                 load_model(model_2),\n",
    "#                 dataloader,\n",
    "#                 percent=percent,\n",
    "#                 device=\"cuda:0\"\n",
    "#             )\n",
    "#         else:\n",
    "#             print(f\"Reusing results for {df_id}\")\n",
    "#     torch.save(res, cache_path)\n",
    "#     return res\n",
    "\n",
    "def compute_results(\n",
    "    model_paths,\n",
    "    dataloader,\n",
    "    cache_path,\n",
    "    percent=1,\n",
    "    load_model=get_resnet18_cifar,\n",
    "    recompute_substring=None\n",
    "):\n",
    "    res = {}\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading existing results from {cache_path}\")\n",
    "        res = torch.load(cache_path)\n",
    "    else:\n",
    "        res = {}\n",
    "    # all_model_pairs = list(itertools.product(anchors + stars, repeat=2))\n",
    "\n",
    "    dataset_root = dataloader.dataset.dataset.__dict__[\"root\"]\n",
    "    dataset_name = dataset_root.split(os.sep)[-1]\n",
    "    # for model_1, model_2 in all_model_pairs:\n",
    "    for model_path in model_paths:\n",
    "\n",
    "        path_split = model_path.split(os.sep)[-2:]\n",
    "        assert len(path_split) == 2\n",
    "        model_type = path_split[0]\n",
    "        model_id = path_split[1].split(\".\")[0]\n",
    "        df_id = f\"{model_type}_{model_id}_{dataset_name}_p{percent}\"\n",
    "        to_recompute = (not df_id in res)\n",
    "        if not to_recompute and recompute_substring is not None:\n",
    "            to_recompute = recompute_substring in df_id\n",
    "\n",
    "        if to_recompute:\n",
    "            print(f\"Computing results for {df_id}\")\n",
    "            res[df_id] = {}\n",
    "            res[df_id][\"margin\"] = margin_on_dataloader(\n",
    "                load_model(model_path),\n",
    "                dataloader,\n",
    "                percent=percent,\n",
    "                device=\"cuda:0\"\n",
    "            )\n",
    "            res[df_id][\"model_type\"] = model_type\n",
    "            res[df_id][\"dataset_name\"] = dataset_name\n",
    "            res[df_id][\"percent\"] = percent\n",
    "        else:\n",
    "            print(f\"Reusing results for {df_id}\")\n",
    "    torch.save(res, cache_path)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://drive.google.com/uc?id=1g-TxEGbORtHmxVEefoJtk2yxSf_mHL28'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_link(\"https://drive.google.com/file/d/1g-TxEGbORtHmxVEefoJtk2yxSf_mHL28/view?usp=drive_link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1g-TxEGbORtHmxVEefoJtk2yxSf_mHL28\n",
      "From (redirected): https://drive.google.com/uc?id=1g-TxEGbORtHmxVEefoJtk2yxSf_mHL28&confirm=t&uuid=98788ac5-cd93-4eba-bc9b-97a69c1064f5\n",
      "To: /scratch_local/arubinstein17-163577/starlight/notebooks/cifar10_resnet18.zip\n",
      "100%|███████████████████████████████████████| 4.37G/4.37G [00:42<00:00, 104MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=1g-TxEGbORtHmxVEefoJtk2yxSf_mHL28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  cifar10_resnet18.zip\n",
      "   creating: ./cifar10_resnet18/\n",
      "   creating: ./cifar10_resnet18/anchors/\n",
      "  inflating: ./cifar10_resnet18/anchors/2oo0upw1.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/3m2c3guk.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/448kfne2.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/52l22gc1.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/5791j5is.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/5hrwt8sd.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/6ids7w54.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/6kxd228s.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/7sckybft.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/7y4wdzel.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/8wmcs3t5.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/ahszhrke.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/atn3ky2k.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/ce0idfac.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/e4fr64ya.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/eq157ykm.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/ezzf8pzr.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/f05nvpkk.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/fkw0sgy5.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/g3qsov5b.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/gbydip83.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/gd0wyvtu.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/hsk4z5ct.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/i9xybq30.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/icpc2wwc.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/ima01h3w.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/ixhqaxw7.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/j33hh4kk.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/jgwp44bl.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/jh0k2kwv.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/jlf1t880.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/jra1jv67.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/kgs9amvk.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/ox2uk04m.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/p4afk6rk.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/p4emcgu4.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/p4fvb7n7.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/q8i1otj3.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/qev36hbl.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/qrw3qvbu.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/qw35l7g4.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/rbdhdhru.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/szgmvbf2.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/ux53i0ja.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/v1uf9cme.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/vo7og34k.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/vt3he185.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/vtvbt443.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/z28eizcb.pt  \n",
      "  inflating: ./cifar10_resnet18/anchors/zagpj9do.pt  \n",
      "   creating: ./cifar10_resnet18/held_out/\n",
      "  inflating: ./cifar10_resnet18/held_out/5bluce0j.pt  \n",
      "  inflating: ./cifar10_resnet18/held_out/j53z28km.pt  \n",
      "  inflating: ./cifar10_resnet18/held_out/soba3yez.pt  \n",
      "  inflating: ./cifar10_resnet18/held_out/t25mz93m.pt  \n",
      "  inflating: ./cifar10_resnet18/held_out/vecgrxkl.pt  \n",
      "   creating: ./cifar10_resnet18/stars/\n",
      "  inflating: ./cifar10_resnet18/stars/0eiwx0xx.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/4s24tjof.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/51y9jsu6.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/52ko7teg.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/5emm5yub.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/5zclde69.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/69kjnr8e.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/6gps5q6c.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/7lvvg6vt.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/82pxe1i8.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/84frwc37.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/8crvzaj1.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/8dirowph.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/8jlh8m2d.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/8l7au5v6.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/8o9awx08.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/9pvinqaq.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/9x4yviaz.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/bezgu0h7.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/by2vpp9d.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/cbk5wpnf.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/cdu3a0jj.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/e35vecib.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/eirtydgk.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/ex2fcs4k.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/gzgzb5q9.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/h2qjwxrq.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/isfg07d8.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/j2inz7uv.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/ld3kvc9z.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/lxaadzad.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/n5sjdrla.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/n8vpmpbj.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/nyolmhfc.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/ovgk6fmw.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/ovq6mpnl.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/p6juczq3.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/p6o2u3b4.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/pajmb0fq.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/r0ispnub.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/rbtifw7r.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/s0gzzdw7.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/ssyfcnh5.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/ue0cyt8u.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/vzwht6g0.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/wrvljast.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/yupmkpsi.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/yw0vl386.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/yyoredii.pt  \n",
      "  inflating: ./cifar10_resnet18/stars/zubysod8.pt  \n"
     ]
    }
   ],
   "source": [
    "# !tar -xzf /scratch_local/arubinstein17-163577/starlight/notebooks/cifar10_resnet18.zip\n",
    "!unzip cifar10_resnet18.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_path = \"./cifar10_resnet18/\"\n",
    "stars_path = os.path.join(cifar_path, \"stars\")\n",
    "anchors_path = os.path.join(cifar_path, \"anchors\")\n",
    "# anchors = os.listdir(\"./cifar10_resnet18/anchors\")\n",
    "anchors = [os.path.join(anchors_path, name) for name in os.listdir(anchors_path)]\n",
    "stars = [os.path.join(stars_path, name) for name in os.listdir(stars_path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_1 = anchors[0]\n",
    "anchor_2 = anchors[1]\n",
    "star_1 = stars[0]\n",
    "star_2 = stars[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using 45000 images for training\n",
      "Using 5000 images for validation\n",
      "Using train transform Compose(\n",
      "    IdentityTransform()\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cifar10_train_dataloader, _, _ = load_cifar10(\n",
    "    batch_size=256,\n",
    "    num_workers=8,\n",
    "    img_size=32,\n",
    "    normalize=True,\n",
    "    resize=False,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    random_crop_resize=False,\n",
    "    random_resize_crop=False,\n",
    "    color_jitter=False,\n",
    "    rotation_range=0,\n",
    "    pad_random_crop=False,\n",
    "    random_one_aug=False,\n",
    "    train_set_fraction=1.0,\n",
    "    return_ds=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in cifar10_train_dataloader:\n",
    "    x, y = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state_dict'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = get_resnet18_cifar(anchor_1, \"resnet18_cifar\", model_settings={\"num_classes\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet18 Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_i = 0\n",
    "class_j = 1\n",
    "model_1 = get_resnet18_cifar(anchor_1)\n",
    "model_2 = get_resnet18_cifar(anchor_2)\n",
    "margin = compute_margin(model_1, model_2, class_i, class_j, x, norm=\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_on_dataloader(get_resnet18_cifar(anchors[0]), get_resnet18_cifar(anchors[1]), cifar10_train_dataloader, percent=0.10, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./cifar10_resnet18/anchors/2oo0upw1.pt',\n",
       " './cifar10_resnet18/anchors/3m2c3guk.pt']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dict(res, to_show=True, filter_dict={}, drop_columns=[], group_aggregate_list=[]):\n",
    "\n",
    "    df = pd.DataFrame.from_dict(res, orient='index')\n",
    "\n",
    "    for column_name, value in filter_dict.items():\n",
    "        df = df[df[column_name] == value]\n",
    "\n",
    "    for column_name in drop_columns:\n",
    "        if column_name == \"index\":\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "        else:\n",
    "            df = df.drop(column_name, axis=1)\n",
    "    print(df)\n",
    "    for new_index in group_aggregate_list:\n",
    "        df = df.groupby(new_index).agg([(f'mean', 'mean'), (f'std', 'std')])\n",
    "\n",
    "    if to_show:\n",
    "        display(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin</th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset_root</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchors_2oo0upw1_cifar10_p0.05</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>anchors</td>\n",
       "      <td>/mnt/qb/work/oh/arubinstein17/datasets/cifar10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchors_3m2c3guk_cifar10_p0.05</th>\n",
       "      <td>0.000080</td>\n",
       "      <td>anchors</td>\n",
       "      <td>/mnt/qb/work/oh/arubinstein17/datasets/cifar10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars_0eiwx0xx_cifar10_p0.05</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>stars</td>\n",
       "      <td>/mnt/qb/work/oh/arubinstein17/datasets/cifar10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars_4s24tjof_cifar10_p0.05</th>\n",
       "      <td>0.000071</td>\n",
       "      <td>stars</td>\n",
       "      <td>/mnt/qb/work/oh/arubinstein17/datasets/cifar10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  margin model_type  \\\n",
       "anchors_2oo0upw1_cifar10_p0.05  0.000083    anchors   \n",
       "anchors_3m2c3guk_cifar10_p0.05  0.000080    anchors   \n",
       "stars_0eiwx0xx_cifar10_p0.05    0.000070      stars   \n",
       "stars_4s24tjof_cifar10_p0.05    0.000071      stars   \n",
       "\n",
       "                                                                  dataset_root  \\\n",
       "anchors_2oo0upw1_cifar10_p0.05  /mnt/qb/work/oh/arubinstein17/datasets/cifar10   \n",
       "anchors_3m2c3guk_cifar10_p0.05  /mnt/qb/work/oh/arubinstein17/datasets/cifar10   \n",
       "stars_0eiwx0xx_cifar10_p0.05    /mnt/qb/work/oh/arubinstein17/datasets/cifar10   \n",
       "stars_4s24tjof_cifar10_p0.05    /mnt/qb/work/oh/arubinstein17/datasets/cifar10   \n",
       "\n",
       "                                percent  \n",
       "anchors_2oo0upw1_cifar10_p0.05     0.05  \n",
       "anchors_3m2c3guk_cifar10_p0.05     0.05  \n",
       "stars_0eiwx0xx_cifar10_p0.05       0.05  \n",
       "stars_4s24tjof_cifar10_p0.05       0.05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin</th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset_root</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchors_2oo0upw1_cifar10_p0.05</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>anchors</td>\n",
       "      <td>/mnt/qb/work/oh/arubinstein17/datasets/cifar10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchors_3m2c3guk_cifar10_p0.05</th>\n",
       "      <td>0.000080</td>\n",
       "      <td>anchors</td>\n",
       "      <td>/mnt/qb/work/oh/arubinstein17/datasets/cifar10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars_0eiwx0xx_cifar10_p0.05</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>stars</td>\n",
       "      <td>/mnt/qb/work/oh/arubinstein17/datasets/cifar10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars_4s24tjof_cifar10_p0.05</th>\n",
       "      <td>0.000071</td>\n",
       "      <td>stars</td>\n",
       "      <td>/mnt/qb/work/oh/arubinstein17/datasets/cifar10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  margin model_type  \\\n",
       "anchors_2oo0upw1_cifar10_p0.05  0.000083    anchors   \n",
       "anchors_3m2c3guk_cifar10_p0.05  0.000080    anchors   \n",
       "stars_0eiwx0xx_cifar10_p0.05    0.000070      stars   \n",
       "stars_4s24tjof_cifar10_p0.05    0.000071      stars   \n",
       "\n",
       "                                                                  dataset_root  \\\n",
       "anchors_2oo0upw1_cifar10_p0.05  /mnt/qb/work/oh/arubinstein17/datasets/cifar10   \n",
       "anchors_3m2c3guk_cifar10_p0.05  /mnt/qb/work/oh/arubinstein17/datasets/cifar10   \n",
       "stars_0eiwx0xx_cifar10_p0.05    /mnt/qb/work/oh/arubinstein17/datasets/cifar10   \n",
       "stars_4s24tjof_cifar10_p0.05    /mnt/qb/work/oh/arubinstein17/datasets/cifar10   \n",
       "\n",
       "                                percent  \n",
       "anchors_2oo0upw1_cifar10_p0.05     0.05  \n",
       "anchors_3m2c3guk_cifar10_p0.05     0.05  \n",
       "stars_0eiwx0xx_cifar10_p0.05       0.05  \n",
       "stars_4s24tjof_cifar10_p0.05       0.05  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_dict(cifar10_resnet18_results, to_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     margin model_type  percent\n",
      "0  0.000083    anchors     0.05\n",
      "1  0.000080    anchors     0.05\n",
      "2  0.000070      stars     0.05\n",
      "3  0.000071      stars     0.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">margin</th>\n",
       "      <th colspan=\"2\" halign=\"left\">percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchors</th>\n",
       "      <td>0.000082</td>\n",
       "      <td>2.162845e-06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>7.760381e-07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              margin               percent     \n",
       "                mean           std    mean  std\n",
       "model_type                                     \n",
       "anchors     0.000082  2.162845e-06    0.05  0.0\n",
       "stars       0.000070  7.760381e-07    0.05  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = plot_dict(cifar10_resnet18_results, to_show=True, filter_dict={}, drop_columns=[\"index\", \"dataset_root\"], group_aggregate_list=[\"model_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     margin model_type\n",
      "0  0.000083    anchors\n",
      "1  0.000080    anchors\n",
      "2  0.000070      stars\n",
      "3  0.000071      stars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">margin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>margin mean</th>\n",
       "      <th>margin std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchors</th>\n",
       "      <td>0.000082</td>\n",
       "      <td>2.162845e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>7.760381e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                margin              \n",
       "           margin mean    margin std\n",
       "model_type                          \n",
       "anchors       0.000082  2.162845e-06\n",
       "stars         0.000070  7.760381e-07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_dict(res, to_show=True, group_by=\"model_type\", filter_by={\"percent\": 0.05})\n",
    "# df = plot_dict(cifar10_resnet18_results, to_show=True, filter_dict={}, group_aggregate_dict={\"model_type\": \"mean\"})\n",
    "df = plot_dict(cifar10_resnet18_results, to_show=True, filter_dict={}, drop_columns=[\"index\", \"dataset_root\", \"percent\"], group_aggregate_dict={\"model_type\": \"margin\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing results from ./cifar10_resnet18_results.pt\n",
      "Computing results for anchors_2oo0upw1_cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:03<00:00, 52.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for anchors_3m2c3guk_cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:03<00:00, 50.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for stars_0eiwx0xx_cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:03<00:00, 51.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for stars_4s24tjof_cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:03<00:00, 50.75it/s]\n"
     ]
    }
   ],
   "source": [
    "cifar10_resnet18_results = compute_results(\n",
    "    anchors[:2] + stars[:2],\n",
    "    cifar10_train_dataloader,\n",
    "    \"./cifar10_resnet18_results.pt\",\n",
    "    percent=0.05,\n",
    "    load_model=get_resnet18_cifar,\n",
    "    # recompute_substring=\"p0\"\n",
    "    recompute_substring=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/anchors/2oo0upw1.pt_./cifar10_resnet18/anchors/3m2c3guk.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 30.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/anchors/2oo0upw1.pt_./cifar10_resnet18/stars/0eiwx0xx.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 32.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/anchors/2oo0upw1.pt_./cifar10_resnet18/stars/4s24tjof.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 32.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/anchors/3m2c3guk.pt_./cifar10_resnet18/anchors/2oo0upw1.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 31.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/anchors/3m2c3guk.pt_./cifar10_resnet18/stars/0eiwx0xx.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/anchors/3m2c3guk.pt_./cifar10_resnet18/stars/4s24tjof.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 31.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/stars/0eiwx0xx.pt_./cifar10_resnet18/anchors/2oo0upw1.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/stars/0eiwx0xx.pt_./cifar10_resnet18/anchors/3m2c3guk.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 31.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/stars/0eiwx0xx.pt_./cifar10_resnet18/stars/4s24tjof.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 31.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/stars/4s24tjof.pt_./cifar10_resnet18/anchors/2oo0upw1.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 31.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/stars/4s24tjof.pt_./cifar10_resnet18/anchors/3m2c3guk.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 31.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results for ./cifar10_resnet18/stars/4s24tjof.pt_./cifar10_resnet18/stars/0eiwx0xx.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [00:05<00:00, 31.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'./cifar10_resnet18/anchors/2oo0upw1.pt_./cifar10_resnet18/anchors/3m2c3guk.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(8.3112e-05),\n",
       " './cifar10_resnet18/anchors/2oo0upw1.pt_./cifar10_resnet18/stars/0eiwx0xx.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(7.4942e-05),\n",
       " './cifar10_resnet18/anchors/2oo0upw1.pt_./cifar10_resnet18/stars/4s24tjof.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(7.3900e-05),\n",
       " './cifar10_resnet18/anchors/3m2c3guk.pt_./cifar10_resnet18/anchors/2oo0upw1.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(8.1999e-05),\n",
       " './cifar10_resnet18/anchors/3m2c3guk.pt_./cifar10_resnet18/stars/0eiwx0xx.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(7.6259e-05),\n",
       " './cifar10_resnet18/anchors/3m2c3guk.pt_./cifar10_resnet18/stars/4s24tjof.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(7.6018e-05),\n",
       " './cifar10_resnet18/stars/0eiwx0xx.pt_./cifar10_resnet18/anchors/2oo0upw1.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(7.5919e-05),\n",
       " './cifar10_resnet18/stars/0eiwx0xx.pt_./cifar10_resnet18/anchors/3m2c3guk.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(7.4457e-05),\n",
       " './cifar10_resnet18/stars/0eiwx0xx.pt_./cifar10_resnet18/stars/4s24tjof.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(7.0220e-05),\n",
       " './cifar10_resnet18/stars/4s24tjof.pt_./cifar10_resnet18/anchors/2oo0upw1.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(7.7402e-05),\n",
       " './cifar10_resnet18/stars/4s24tjof.pt_./cifar10_resnet18/anchors/3m2c3guk.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(7.4934e-05),\n",
       " './cifar10_resnet18/stars/4s24tjof.pt_./cifar10_resnet18/stars/0eiwx0xx.pt_/mnt/qb/work/oh/arubinstein17/datasets/cifar10_p0.05': tensor(7.1486e-05)}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_results(\n",
    "    anchors[:2],\n",
    "    stars[:2],\n",
    "    cifar10_train_dataloader,\n",
    "    \"./cifar10_resnet18_results.pt\",\n",
    "    percent=0.05,\n",
    "    load_model=get_resnet18_cifar,\n",
    "    recompute_substring=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 176/176 [01:42<00:00,  1.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(8.2205e-05)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin_on_dataloader(get_resnet18_cifar(anchors[0]), get_resnet18_cifar(anchors[1]), cifar10_train_dataloader, percent=1.00, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.50s/it]\n",
      "100it [00:00, 2172.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         6317 function calls (6057 primitive calls) in 16.220 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       20   14.986    0.749   14.986    0.749 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "       40    0.828    0.021    0.828    0.021 {built-in method torch.conv2d}\n",
      "       40    0.195    0.005    0.195    0.005 {built-in method torch.batch_norm}\n",
      "       34    0.069    0.002    0.069    0.002 {built-in method torch.relu}\n",
      "       90    0.026    0.000    0.041    0.000 297611172.py:82(compute_margin)\n",
      "       16    0.026    0.002    1.090    0.068 resnet_cifar_std.py:36(forward)\n",
      "        2    0.016    0.008    0.016    0.008 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "      142    0.015    0.000    0.015    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.013    0.013   16.219   16.219 <string>:1(<module>)\n",
      "      180    0.011    0.000    0.011    0.000 {method 'abs' of 'torch._C.TensorBase' objects}\n",
      "      110    0.006    0.000    0.006    0.000 {method 'sum' of 'torch._C.TensorBase' objects}\n",
      "        1    0.005    0.005   16.206   16.206 297611172.py:20(compute_margin_for_batch)\n",
      "       40    0.002    0.000    0.002    0.000 {method 'add_' of 'torch._C.TensorBase' objects}\n",
      "       91    0.002    0.000    0.002    0.000 {method 'mean' of 'torch._C.TensorBase' objects}\n",
      "    124/2    0.001    0.000    1.130    0.565 module.py:1513(_call_impl)\n",
      "       40    0.001    0.000    0.200    0.005 batchnorm.py:141(forward)\n",
      "        2    0.001    0.000    1.130    0.565 resnet_cifar_std.py:97(forward)\n",
      "       14    0.001    0.000    0.002    0.000 std.py:464(format_meter)\n",
      "    124/2    0.001    0.000    1.130    0.565 module.py:1507(_wrapped_call_impl)\n",
      "      418    0.001    0.000    0.001    0.000 module.py:1675(__getattr__)\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch._C._nn.avg_pool2d}\n",
      "       20    0.001    0.000    0.001    0.000 {built-in method torch.ones_like}\n",
      "      144    0.001    0.000    0.001    0.000 {built-in method torch._C._get_tracing_state}\n",
      "       40    0.001    0.000    0.197    0.005 functional.py:2451(batch_norm)\n",
      "       52    0.000    0.000    0.000    0.000 socket.py:621(send)\n",
      "       20    0.000    0.000   14.988    0.749 _tensor.py:463(backward)\n",
      "       40    0.000    0.000    0.828    0.021 conv.py:451(_conv_forward)\n",
      "      112    0.000    0.000    0.019    0.000 std.py:1160(__iter__)\n",
      "       20    0.000    0.000   14.987    0.749 __init__.py:164(backward)\n",
      "       18    0.000    0.000    0.001    0.000 iostream.py:655(write)\n",
      "       40    0.000    0.000    0.000    0.000 functional.py:2434(_verify_batch_size)\n",
      "       20    0.000    0.000   14.990    0.750 297611172.py:69(get_grad)\n",
      "       40    0.000    0.000    0.829    0.021 conv.py:459(forward)\n",
      "       20    0.000    0.000    0.001    0.000 __init__.py:59(_make_grads)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._nn.linear}\n",
      "     24/8    0.000    0.000    1.090    0.136 container.py:215(forward)\n",
      "       34    0.000    0.000    0.070    0.002 functional.py:1462(relu)\n",
      "      604    0.000    0.000    0.000    0.000 utils.py:375(<genexpr>)\n",
      "       52    0.000    0.000    0.001    0.000 iostream.py:259(schedule)\n",
      "       10    0.000    0.000    0.016    0.002 std.py:1198(update)\n",
      "       18    0.000    0.000    0.016    0.001 iostream.py:592(flush)\n",
      "       60    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}\n",
      "       26    0.000    0.000    0.000    0.000 std.py:400(format_interval)\n",
      "       62    0.000    0.000    0.000    0.000 std.py:231(__call__)\n",
      "       20    0.000    0.000    0.000    0.000 _tensor.py:996(__len__)\n",
      "       42    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.TensorBase' objects}\n",
      "       18    0.000    0.000    0.000    0.000 threading.py:228(__init__)\n",
      "       40    0.000    0.000    0.000    0.000 batchnorm.py:418(_check_input_dim)\n",
      "       14    0.000    0.000    0.000    0.000 std.py:1446(format_dict)\n",
      "       14    0.000    0.000    0.002    0.000 std.py:1150(__str__)\n",
      "      590    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}\n",
      "       24    0.000    0.000    0.000    0.000 container.py:207(__iter__)\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "       20    0.000    0.000    0.000    0.000 std.py:102(acquire)\n",
      "       24    0.000    0.000    0.000    0.000 utils.py:273(_is_ascii)\n",
      "       18    0.000    0.000    0.015    0.001 threading.py:280(wait)\n",
      "       70    0.000    0.000    0.000    0.000 threading.py:1089(is_alive)\n",
      "       14    0.000    0.000    0.019    0.001 std.py:1464(display)\n",
      "        2    0.000    0.000    0.003    0.001 std.py:952(__init__)\n",
      "      114    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method torch._C._are_functorch_transforms_active}\n",
      "       12    0.000    0.000    0.017    0.001 std.py:1325(refresh)\n",
      "       14    0.000    0.000    0.016    0.001 std.py:457(print_status)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method now}\n",
      "       12    0.000    0.000    0.000    0.000 std.py:186(__format__)\n",
      "       74    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "       18    0.000    0.000    0.015    0.001 threading.py:556(wait)\n",
      "       32    0.000    0.000    0.016    0.000 utils.py:194(inner)\n",
      "      144    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "       14    0.000    0.000    0.016    0.001 std.py:451(fp_write)\n",
      "       40    0.000    0.000    0.000    0.000 __init__.py:36(__get__)\n",
      "       20    0.000    0.000    0.000    0.000 std.py:106(release)\n",
      "       14    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "       70    0.000    0.000    0.000    0.000 threading.py:1035(_wait_for_tstate_lock)\n",
      "      110    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "       18    0.000    0.000    0.001    0.000 iostream.py:577(_schedule_flush)\n",
      "       52    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
      "       14    0.000    0.000    0.000    0.000 utils.py:374(_text_width)\n",
      "       12    0.000    0.000    0.000    0.000 std.py:153(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}\n",
      "       18    0.000    0.000    0.000    0.000 threading.py:521(__init__)\n",
      "       40    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "       14    0.000    0.000    0.001    0.000 utils.py:378(disp_len)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:686(_decr_instances)\n",
      "      252    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       18    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000   16.220   16.220 {built-in method builtins.exec}\n",
      "        4    0.000    0.000    0.002    0.001 std.py:1265(close)\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "      104    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:333(_screen_shape_linux)\n",
      "       40    0.000    0.000    0.000    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
      "       18    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "       18    0.000    0.000    0.000    0.000 threading.py:1314(current_thread)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C.TensorBase' objects}\n",
      "       20    0.000    0.000    0.000    0.000 __init__.py:154(_tensor_or_tensors_to_tuple)\n",
      "       24    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "        2    0.000    0.000    0.000    0.000 std.py:663(__new__)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:59(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "       36    0.000    0.000    0.000    0.000 threading.py:1065(ident)\n",
      "       70    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method fromtimestamp}\n",
      "       18    0.000    0.000    0.000    0.000 threading.py:256(__enter__)\n",
      "       36    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "       72    0.000    0.000    0.000    0.000 threading.py:529(is_set)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 std.py:679(_get_free_pos)\n",
      "       18    0.000    0.000    0.000    0.000 threading.py:268(_acquire_restore)\n",
      "        4    0.000    0.000    0.000    0.000 std.py:1286(fp_write)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "       36    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:213(__init__)\n",
      "        2    0.000    0.000    0.001    0.001 std.py:438(status_printer)\n",
      "       12    0.000    0.000    0.000    0.000 utils.py:108(__init__)\n",
      "       18    0.000    0.000    0.000    0.000 threading.py:259(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "       18    0.000    0.000    0.000    0.000 threading.py:271(_is_owned)\n",
      "        2    0.000    0.000    0.000    0.000 functools.py:392(__get__)\n",
      "       18    0.000    0.000    0.000    0.000 threading.py:265(_release_save)\n",
      "        8    0.000    0.000    0.000    0.000 std.py:110(__enter__)\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        2    0.000    0.000    0.000    0.000 linear.py:115(forward)\n",
      "       18    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        4    0.000    0.000    0.000    0.000 _weakrefset.py:27(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:107(remove)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "       18    0.000    0.000    0.000    0.000 {method 'get' of 'ContextVar' objects}\n",
      "        4    0.000    0.000    0.000    0.000 _weakrefset.py:21(__enter__)\n",
      "       12    0.000    0.000    0.000    0.000 std.py:167(colour)\n",
      "        2    0.000    0.000    0.000    0.000 os.py:674(__getitem__)\n",
      "       12    0.000    0.000    0.000    0.000 utils.py:112(__format__)\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:347(<listcomp>)\n",
      "       18    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:82(add)\n",
      "        1    0.000    0.000    0.000    0.000 _contextlib.py:149(__new__)\n",
      "        6    0.000    0.000    0.000    0.000 utils.py:152(wrapper_setattr)\n",
      "       18    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        8    0.000    0.000    0.000    0.000 std.py:113(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 std.py:1157(__hash__)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:760(get_lock)\n",
      "       18    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 os.py:754(encode)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:187(disable_on_exception)\n",
      "        4    0.000    0.000    0.000    0.000 _weakrefset.py:17(__init__)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:125(__eq__)\n",
      "        1    0.000    0.000    0.000    0.000 grad_mode.py:134(__enter__)\n",
      "       12    0.000    0.000    0.000    0.000 std.py:163(colour)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:266(_supports_unicode)\n",
      "       18    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 std.py:226(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:156(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 std.py:1153(_comparable)\n",
      "        2    0.000    0.000    0.000    0.000 _monitor.py:94(report)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}\n",
      "        2    0.000    0.000    0.000    0.000 std.py:682(<setcomp>)\n",
      "       18    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:222(__eq__)\n",
      "        1    0.000    0.000    0.000    0.000 grad_mode.py:138(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 _weakrefset.py:53(_commit_removals)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x56192b9fe020}\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1147(__del__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:252(_is_utf)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:364(fileno)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:282(_screen_shape_wrapper)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1301(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)"
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "margin = compute_margin_for_batch(model_1, model_2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0003)\n"
     ]
    }
   ],
   "source": [
    "print(margin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
